{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Processing\n",
        "\n",
        "Semantic processing involves understanding the meaning and relationships between words and phrases in natural language.\n",
        "\n",
        "* Two important tasks in semantic processing are\n",
        "1. Word sense disambiguation\n",
        "2. Textual entailment."
      ],
      "metadata": {
        "id": "KdiarHofH1g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Word Sence Disambiguation\n",
        "\n",
        "Sure! Let's break down Word Sense Disambiguation (WSD) step by step:\n",
        "\n",
        "- **Word Sense Disambiguation (WSD)**\n",
        "\n",
        "This task aims to determine the correct meaning of a word within a given context. Words often have multiple meanings depending on the context in which they are used. WSD helps in identifying the appropriate sense of a word in a particular context.\n",
        "\n",
        "  - **Task**: Determine correct meaning of a word in a given context.\n",
        "  - **Contextual Ambiguity**: Words possess multiple meanings based on context.\n",
        "  - **Purpose**: Identifying suitable sense of a word within specific context.\n",
        "  - **Importance**: Facilitates accurate understanding of text and language comprehension."
      ],
      "metadata": {
        "id": "n1XRPgwKH8xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlFIwPgqJovp",
        "outputId": "7b40b457-b521-4d1f-dfab-b6c487abd4f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thxjVURBHwjf",
        "outputId": "fcee0d66-2276-4664-8f62-d2b01162197f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: I, Synset: Synset('iodine.n.01')\n",
            "Word: went, Synset: Synset('survive.v.01')\n",
            "Word: to, Synset: None\n",
            "Word: the, Synset: None\n",
            "Word: bank, Synset: Synset('savings_bank.n.02')\n",
            "Word: to, Synset: None\n",
            "Word: deposit, Synset: Synset('deposit.n.04')\n",
            "Word: some, Synset: Synset('some.a.01')\n",
            "Word: money, Synset: Synset('money.n.03')\n",
            "Word: ., Synset: None\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "# Example sentence for Word Sense Disambiguation\n",
        "sentence = \"I went to the bank to deposit some money.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "# Perform Word Sense Disambiguation using Lesk algorithm\n",
        "for word in tokens:\n",
        "    synset = lesk(tokens, word)\n",
        "    print(f\"Word: {word}, Synset: {synset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Textual Entailment\n",
        "\n",
        "- **Textual Entailment**\n",
        "\n",
        "Textual entailment is the task of determining whether one piece of text logically entails another. In other words, if the meaning of one text (the hypothesis) can be inferred or logically deduced from another text (the premise).\n",
        "\n",
        "  - **Task**: Determine logical inference between texts.\n",
        "  - **Logical Relationship**: Assess if meaning of one text can be inferred from another.\n",
        "  - **Purpose**: Establish logical connection between two texts.\n",
        "  - **Importance**: Crucial for natural language understanding, question answering, and inference-based applications."
      ],
      "metadata": {
        "id": "CygmjoGJJ-FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Example sentences for Textual Entailment\n",
        "premise = \"The cat is on the mat.\"\n",
        "hypothesis1 = \"The cat is asleep.\"\n",
        "hypothesis2 = \"The mat is on the cat.\"\n",
        "\n",
        "# Tokenize the sentences\n",
        "premise_tokens = word_tokenize(premise)\n",
        "hypothesis1_tokens = word_tokenize(hypothesis1)\n",
        "hypothesis2_tokens = word_tokenize(hypothesis2)\n",
        "\n",
        "# Check if hypothesis1 entails the premise\n",
        "entails_1 = all(wn.synsets(word1) and wn.synsets(word2) and wn.synsets(word1)[0].entailments() <= wn.synsets(word2)[0].entailments()\n",
        "                for word1, word2 in zip(premise_tokens, hypothesis1_tokens))\n",
        "print(f\"Hypothesis 1 entails the premise: {entails_1}\")\n",
        "\n",
        "# Check if hypothesis2 entails the premise\n",
        "entails_2 = all(wn.synsets(word1) and wn.synsets(word2) and wn.synsets(word1)[0].entailments() <= wn.synsets(word2)[0].entailments()\n",
        "                for word1, word2 in zip(premise_tokens, hypothesis2_tokens))\n",
        "print(f\"Hypothesis 2 entails the premise: {entails_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU_oydJYJh01",
        "outputId": "10604252-c270-4199-e642-37ca68dda5cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypothesis 1 entails the premise: False\n",
            "Hypothesis 2 entails the premise: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swMicFCyKL6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}